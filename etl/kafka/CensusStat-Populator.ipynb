{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"456ef991-02da-49bd-96ff-82b62cea683c","showTitle":false,"title":""}},"source":["# `CensusStat` Populator\n","*Populates all tables(`CensusStat`, `Demographic`, `State`, and `Metric`) related to Census and CDC data.* Replaces all individual populators."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f8489d55-6da5-4116-88c4-875e2a3388b9","showTitle":false,"title":""}},"source":["## Step 1: Set-Up"]},{"cell_type":"code","execution_count":1,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"44a6c2e5-de16-4d78-8ea7-d8eb7e49afa7","showTitle":false,"title":""}},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'confluent_kafka'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/var/folders/23/5p0ycg913qq12vh3l31n93zc0000gn/T/ipykernel_14595/837342991.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfluent_kafka\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdminClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNewTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'confluent_kafka'"]}],"source":["# Imports\n","import uuid\n","from confluent_kafka.admin import AdminClient, NewTopic\n","from pyspark.sql.functions import col\n","from pyspark.sql.functions import lit\n","from pyspark.sql.types import FloatType\n","from pyspark.sql.types import StringType\n","import pandas as pd\n","\n","# Get config\n","from config import user\n","from config import password"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"aa5e1160-1589-49b7-a9de-5014c78b0f57","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\">/mnt/jacklynn/census has been unmounted.\n","</div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\">/mnt/jacklynn/census has been unmounted.\n</div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Mount point through Oauth security.\n","storageAccount = \"gen10datafund2205\"\n","storageContainer = \"group5container\"\n","clientSecret = \"-ZS8Q~NwOKfwEpVOg3Teb1pPtxDbz616XjlXLbuU\"\n","clientid = \"2ca50102-5717-4373-b796-39d06568588d\"\n","mount_point = \"/mnt/jacklynn/census\" \n","\n","# Configuration dictionary\n","configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n","       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n","       \"fs.azure.account.oauth2.client.id\": clientid,\n","       \"fs.azure.account.oauth2.client.secret\": clientSecret,\n","       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/d46b54b2-a652-420b-aa5a-2ef7f8fc706e/oauth2/token\",\n","       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n","\n","# Unmount if exists\n","try: \n","    dbutils.fs.unmount(mount_point)\n","except:\n","    pass\n","\n","# Mount to database\n","dbutils.fs.mount(\n","    source = \"abfss://\"+storageContainer+\"@\"+storageAccount+\".dfs.core.windows.net/\",\n","    mount_point = mount_point,\n","    extra_configs = configs)\n","\n","# Table variables\n","database = \"group5database\"\n","user = \"jacklynn\"\n","password  = 'Peanut-Hazel-Tails-1500-Cat!!'\n","server = \"gen10-data-fundamentals-22-05-sql-server.database.windows.net\"\n","port = \"1433\""]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3cb0454a-5c37-443d-a073-262f0367f71c","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/jacklynn/census/CGM_Data.csv</td><td>CGM_Data.csv</td><td>35978185</td><td>1659468631000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/Diabetes Prevalence in the US by State and Demographic.csv</td><td>Diabetes Prevalence in the US by State and Demographic.csv</td><td>180068</td><td>1659497875000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/Education by state.csv</td><td>Education by state.csv</td><td>3516</td><td>1659576860000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/ExerciseData_2013_150min.csv</td><td>ExerciseData_2013_150min.csv</td><td>1544</td><td>1659645073000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/Food Insecurity.csv</td><td>Food Insecurity.csv</td><td>6779</td><td>1659533925000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/Income Brackets by State.csv</td><td>Income Brackets by State.csv</td><td>4675</td><td>1659578726000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/U.S. NHANES Survey Data.csv</td><td>U.S. NHANES Survey Data.csv</td><td>1005266</td><td>1659710519000</td></tr><tr><td>dbfs:/mnt/jacklynn/census/chinese-diabetes-clean.csv</td><td>chinese-diabetes-clean.csv</td><td>33367142</td><td>1659541878000</td></tr></tbody></table></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"aggData":[],"aggError":"","aggOverflow":false,"aggSchema":[],"aggSeriesLimitReached":false,"aggType":"","arguments":{},"columnCustomDisplayInfos":{},"data":[["dbfs:/mnt/jacklynn/census/CGM_Data.csv","CGM_Data.csv",35978185,1659468631000],["dbfs:/mnt/jacklynn/census/Diabetes Prevalence in the US by State and Demographic.csv","Diabetes Prevalence in the US by State and Demographic.csv",180068,1659497875000],["dbfs:/mnt/jacklynn/census/Education by state.csv","Education by state.csv",3516,1659576860000],["dbfs:/mnt/jacklynn/census/ExerciseData_2013_150min.csv","ExerciseData_2013_150min.csv",1544,1659645073000],["dbfs:/mnt/jacklynn/census/Food Insecurity.csv","Food Insecurity.csv",6779,1659533925000],["dbfs:/mnt/jacklynn/census/Income Brackets by State.csv","Income Brackets by State.csv",4675,1659578726000],["dbfs:/mnt/jacklynn/census/U.S. NHANES Survey Data.csv","U.S. NHANES Survey Data.csv",1005266,1659710519000],["dbfs:/mnt/jacklynn/census/chinese-diabetes-clean.csv","chinese-diabetes-clean.csv",33367142,1659541878000]],"datasetInfos":[],"dbfsResultPath":null,"isJsonSchema":true,"metadata":{"isDbfsCommandResult":false},"overflow":false,"plotOptions":{"customPlotOptions":{},"displayType":"table","pivotAggregation":null,"pivotColumns":null,"xColumns":null,"yColumns":null},"removedWidgets":[],"schema":[{"metadata":"{}","name":"path","type":"\"string\""},{"metadata":"{}","name":"name","type":"\"string\""},{"metadata":"{}","name":"size","type":"\"long\""},{"metadata":"{}","name":"modificationTime","type":"\"long\""}],"type":"table"}},"output_type":"display_data"}],"source":["%fs \n","ls /mnt/jacklynn/census"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fde70c6b-00a9-4560-a521-d58a5caee82e","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Helper function: read in table\n","def readInTable(table_name):\n","    df = spark.read.format(\"jdbc\") \\\n","        .option(\"url\", f\"jdbc:sqlserver://{server}:{port};databaseName={database};\") \\\n","        .option(\"dbtable\", table_name).option(\"user\", user).option(\"password\", password) \\\n","        .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n","        .load()\n","    return df\n","\n","# Helper function: read in file\n","def readInFile(f):\n","    df = spark.read.options(\n","        inferSchema='True',\n","        delimiter=',',\n","        header='True'\n","        ).csv(f)\n","    return df\n","\n","# Helper function: write in table\n","def saveToTable(df, table, change='append'):\n","    df.write.format('jdbc').option(\"url\", f\"jdbc:sqlserver://{server}:1433;databaseName={database};\") \\\n","                .mode(change) \\\n","                .option(\"dbtable\", table) \\\n","                .option(\"user\", user) \\\n","                .option(\"password\", password) \\\n","                .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\") \\\n","                .save()\n","\n","# Helper function: convert table into dictionary converter\n","def formDictConverter(table, key, value):\n","    df = readInTable(table)\n","    converter = dict()\n","    data = df.select([key, value]).distinct().toPandas()[[key, value]]\n","    keys = data[key].to_list()\n","    for this_key in keys:\n","        converter[this_key] = data.loc[data[key] == this_key][value].to_list()[0]\n","    return converter"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"86eb5e48-9f5b-4eef-b730-c7f171edeea1","showTitle":false,"title":""}},"source":["## Step 2: Populate `Metric` Database"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"e25eb7e6-9819-4b2a-a3c7-88115f019a26","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Write function for adding metric data\n","def addMetrics(metrics, measurements, overwrite=False):\n","    \n","    # Get table connection already\n","    table_met = \"dbo.Metric\"\n","    df_met_existing = readInTable(table_met)\n","    \n","    # Get stating value\n","    j = 0\n","    if (overwrite != True):\n","        j = df_cats.agg({\"metricID\": \"max\"}).collect()[0]['max(metricID)'] + 1\n","    \n","    # Iterate through each metric\n","    data = []\n","    for i in range(len(metrics)):\n","        \n","        # Get this iterations metric and measurement\n","        metric = metrics[i]\n","        measurement = measurements[i]\n","        \n","        # Check to see if the metric is already in database\n","        if (df_met_existing.filter(df_met_existing['metric'] == metric).count() > 0 and overwrite == False):\n","            print(f'\"{metric}\" is already in database!')\n","        else:\n","            \n","            # Convert this metric to dictionary entry\n","            dict_metric = dict()\n","            dict_metric['metricID'] = j\n","            j += 1\n","            dict_metric['metric'] = metric\n","            dict_metric['unit'] = measurement\n","            data.append(dict_metric)\n","    \n","    # Convert metrics to dataframe\n","    df_metric = spark.createDataFrame(data) \n","    \n","    # Overwrite save to SQL\n","    if (overwrite):\n","        saveToTable(df_metric, table_met, change='overwrite')\n","    \n","    # Append save to SQL\n","    else:\n","        saveToTable(df_metric, table_met)\n","    \n","    # Return dictionary with metric conversions\n","    return formDictConverter(table_met, 'metric', 'metricID')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5266bfbb-6e63-4fc9-9dee-b3b0bc0789af","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Add all metrics to database\n","metrics = ['diabetes', 'highest education', 'exercise (150+ min/wk)', 'food security', 'very low food security', 'income bracket']\n","measurements = ['percentage', 'percentage', 'percentage', 'percentage', 'percertage', 'percentage']\n","metricToID = addMetrics(metrics, measurements, overwrite=True)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4b039133-4e6c-495c-b8d5-fef6e9f94306","showTitle":false,"title":""}},"source":["## Step 3: Populate `State` Database"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9bbda984-ee5d-447a-b1db-3806caef56fd","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Write function for adding states data\n","def addStates():\n","    \n","    # Get states data\n","    df_states = readInFile('/mnt/jacklynn/census/Diabetes Prevalence in the US by State and Demographic.csv')\n","\n","    # Extract states data\n","    dict_states = []\n","    states = df_states.select(['LocationAbbr', 'LocationDesc']).distinct().toPandas()\n","    for state in states['LocationAbbr'].to_list():\n","        this_state = dict()\n","        this_state['stateID'] = state\n","        this_state['name'] = states.loc[states['LocationAbbr'] == state]['LocationDesc'].to_list()[0]\n","        dict_states.append(this_state)\n","    \n","    # Add Washington DC\n","    dc = dict()\n","    dc['stateID'] = 'DC'\n","    dc['name'] = 'Washington D.C.'\n","    dict_states.append(dc)\n","\n","    # Convert to DataFrame\n","    df_states = spark.createDataFrame(dict_states)\n","\n","    # Save state data to Demographic SQL table\n","    table_states = \"dbo.State\"\n","    saveToTable(df_states, table_states, change='overwrite')\n","    \n","    # Return dictionary with states conversions\n","    return formDictConverter(table_states, 'name', 'stateID')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6766ab22-1384-42e6-90df-933ead2b2a4b","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Add all states to database\n","statesToID = addStates()\n","\n","# Add national and DC value\n","statesToID['National'] = statesToID['United States']\n","statesToID['District of Columbia'] = statesToID['Washington D.C.']\n","statesToID['U.S. total'] = statesToID['United States']\n","statesToID['U.S.'] = statesToID['United States']"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"73acbf77-f310-4290-af3c-f9a0cca62939","showTitle":false,"title":""}},"source":["## Part 4: Populate `Demographic` Database"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4f1f3bd0-03a0-4012-8760-8297a2a04bdc","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Get starting demoID\n","table_demo = \"dbo.Demographic\"\n","df_demo = readInTable(table_demo)\n","j = df_demo.agg({\"demoID\": \"max\"}).collect()[0]['max(demoID)'] + 1\n","\n","# Write function for adding states data\n","def addDemographics():\n","    \n","    # Useful variable\n","    schema = ['demoID', 'demo_group', 'category']\n","    table_demo = \"dbo.Demographic\"\n","    \n","    # Helper function\n","    \n","    # Helper function: create category\n","    def createCategory(group, category):\n","        global j\n","        demoID = j\n","        j += 1\n","        return [demoID, group, category]\n","    \n","    # Helper function: remove duplicates\n","    def dedup(starting_list):\n","        used_list = readInTable(\"dbo.Demographic\").select(['demo_group']).toPandas()['demo_group'].to_list()\n","        for demo in starting_list:\n","            if demo in used_list or demo.capitalize() in used_list or demo.lower() in used_list:\n","                starting_list.remove(demo)\n","        return starting_list\n","    \n","    # DIABETES DATA\n","    \n","    # Get diabetes prevalence demographics\n","    df_diabetes = readInFile('/mnt/jacklynn/census/Diabetes Prevalence in the US by State and Demographic.csv')\n","    \n","    # Get categories\n","    diabetes_demos = df_diabetes.select('Stratification1').distinct().toPandas()['Stratification1'].to_list()\n","    \n","    # Iterate through each one and remove those that are already in list\n","    diabetes_demos = dedup(diabetes_demos)\n","    diabetes_demos.remove('Overall') # Removed to be replaced with general class\n","    \n","    # Only if values exist save\n","    if (len(diabetes_demos) != 0):\n","    \n","        # Add all of demos under 'race/ethnicity' category\n","        diabetes_demo_map = map(lambda x: createCategory(x, 'race/ethnicity'), diabetes_demos)\n","        df_diabetes_demos = spark.createDataFrame(data = diabetes_demo_map, schema = schema)\n","\n","        # Save to table\n","        saveToTable(df_diabetes_demos, table_demo)\n","    \n","    # EDUCATION DATA\n","    \n","    # Get education demographics\n","    df_education = readInFile('/mnt/jacklynn/census/Education by state.csv')\n","    \n","    # Get demos\n","    education_demos = df_education.schema.names\n","    for rem_cat in ['_c0', 'State', 'Total Population']:\n","        education_demos.remove(rem_cat)\n","        \n","    # Iterate through each one and remove those that are already in list\n","    education_demos = dedup(education_demos)\n","    \n","    # Only if values exist save\n","    if (len(education_demos) != 0):\n","    \n","        # Add all of demos under 'education level' category\n","        education_demo_map = map(lambda x: createCategory(x, 'education level'), education_demos)\n","        df_education_demos = spark.createDataFrame(data = education_demo_map, schema = schema)\n","\n","        # Save to table\n","        saveToTable(df_education_demos, table_demo)\n","    \n","    # EXERCISE DATA (and FOOD SECURITY DATA)\n","    \n","    # Add only general category\n","    exercise_demos = ['General']\n","    exercise_demos = dedup(exercise_demos)\n","    \n","    # Only if values exist save\n","    if (len(exercise_demos) != 0):\n","    \n","        education_demo_map = map(lambda x: createCategory(x, 'general'), exercise_demos)\n","        df_exercise_demos = spark.createDataFrame(data = education_demo_map, schema = schema)\n","\n","        # Save to table\n","        saveToTable(df_exercise_demos, table_demo)\n","    \n","    # INCOME DATA\n","    \n","    # Get income demographics\n","    df_income = readInFile('/mnt/jacklynn/census/Income Brackets by State.csv')\n","    \n","    # Get demos\n","    income_demos = df_income.schema.names\n","    for rem_cat in ['_c0', 'State', 'Total']:\n","        income_demos.remove(rem_cat)\n","        \n","    # Iterate through each one and remove those that are already in list\n","    income_demos = dedup(income_demos)\n","    \n","    # Only if values exist save\n","    if (len(income_demos) != 0):\n","    \n","        # Add all of demos under 'income bracket' category\n","        income_demo_map = map(lambda x: createCategory(x, 'income bracket'), income_demos)\n","        df_income_demos = spark.createDataFrame(data = income_demo_map, schema = schema)\n","\n","        # Save to table\n","        saveToTable(df_income_demos, table_demo)\n","    \n","    # Return dictionary with states conversions\n","    return formDictConverter(table_demo, 'demo_group', 'demoID')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f9ca3bd7-6461-4592-a45e-c653c1630b13","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Add all demos to database\n","demosToID = addDemographics()\n","\n","# Add in uppercase versions of 'Female' and 'Male'\n","demosToID['Female'] = demosToID['female']\n","demosToID['Male'] = demosToID['male']\n","\n","# Add 'Overall' to track to 'General'\n","demosToID['Overall'] = demosToID['General']"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"df905307-2ff9-43ac-b6fe-49b4d1d14668","showTitle":false,"title":""}},"source":["## Part 5: Populate `CensusStat` Database"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"13a39551-9ea9-466a-b4be-1da2cb3c0c19","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# Helper function: rename tables\n","def renameCols(df, prev_cols, new_cols):\n","    for i in range(len(prev_cols)):\n","        df = df.withColumnRenamed(prev_cols[i], new_cols[i])\n","    return df\n","\n","# Helper function: drop columns\n","def dropCols(df, drop_cols):\n","    for this_cols in drop_cols:\n","        try:\n","            df = df.drop(col(this_cols))\n","        except:\n","            df = df.drop(this_cols)\n","    return df\n","\n","# Helper function: add columns with all the same values\n","def addCols(df, colNames, addValues):\n","    for i in range(len(colNames)):\n","        df = df.withColumn(colNames[i], lit(addValues[i]))\n","    return df\n","\n","# Helper function: convert demo to demoID\n","def catToID(df, merge_val, cat_cols, dictionary):\n","    df_replace = df.select(cat_cols + merge_val).toPandas()\n","    for cat in cat_cols:\n","        df_replace =  df_replace.replace({cat: dictionary})\n","        try:\n","            df = df.drop(col(cat))\n","        except:\n","            df = df.drop(cat)\n","    df_replace = spark.createDataFrame(df_replace)\n","    df = df.join(df_replace, on=merge_val)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6551a071-25f0-4ec7-92c0-ce142b198f50","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# DIABETES DATA\n","df_diabetes = readInFile('/mnt/jacklynn/census/Diabetes Prevalence in the US by State and Demographic.csv')\n","\n","# Replace values of interest\n","df_diabetes = catToID(df_diabetes, ['_c0'], ['Stratification1'], demosToID)\n","df_diabetes = renameCols(df_diabetes, ['LocationAbbr', 'Stratification1', 'YearEnd', 'DataValue'], ['stateID', 'demoID', 'year', 'value'])\n","df_diabetes = dropCols(df_diabetes, ['LocationDesc', 'personID', '_c0'])\n","df_diabetes = df_diabetes.withColumn(\"metricID\", lit(metricToID['diabetes']))\n","\n","# Save database\n","table_census = \"dbo.CensusStat\"\n","saveToTable(df_diabetes, table_census, change='overwrite')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"39ab4f0e-2107-4748-b1f8-16bebda23ddb","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# EDUCATION DATA\n","df_education = readInFile('/mnt/jacklynn/census/Education by state.csv')\n","\n","# Convert state values\n","df_education = catToID(df_education, ['_c0'], ['State'], statesToID)\n","\n","# Get columns to iterate through\n","cats = df_education.schema.names\n","for rem_cat in ['_c0', 'State', 'Total Population']:\n","    cats.remove(rem_cat)\n","\n","# Add each category individually\n","for cat in cats:\n","    \n","    # Get percentage of population\n","    this_df_perc = df_education.select(['Total Population', cat, 'State']).toPandas()\n","    population = (this_df_perc[cat].str.replace(',','').astype(int) / this_df_perc['Total Population'].str.replace(',','').astype(int) * 100)\n","    population = population.to_frame()\n","    population = pd.concat([this_df_perc['State'], population], axis=1)\n","    this_df = spark.createDataFrame(population, schema=['stateID', 'value']) \n","    \n","    # Add other columns\n","    names = ['metricID', 'demoID', 'year']\n","    vals = [metricToID['highest education'], demosToID[cat], 2017]\n","    this_df = addCols(this_df, names, vals)\n","\n","    # Add the data to SQL\n","    saveToTable(this_df, table_census)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"eb911edd-809a-48ef-aac5-fb4f2a668e4e","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# EXERCISE DATA\n","df_exercise = readInFile('/mnt/jacklynn/census/ExerciseData_2013_150min.csv')\n","\n","# Drop unnecessary columns\n","df_exercise = dropCols(df_exercise, ['Low_Confidence_Limit', 'High_Confidence_Limit', 'Sample_Size'])\n","\n","# Rename columns to correct names\n","df_exercise = renameCols(df_exercise, ['YearStart', 'Data_value', 'LocationDesc'], ['year', 'value', 'stateID'])\n","\n","# Convert state values\n","df_exercise = catToID(df_exercise, ['_c0'], ['stateID'], statesToID)\n","\n","# Add other columns\n","names = ['metricID', 'demoID']\n","vals = [metricToID['exercise (150+ min/wk)'], demosToID['General'], 2017]\n","df_exercise = addCols(df_exercise, names, vals)\n","\n","# Remove unnecessary column\n","df_exercise = dropCols(df_exercise, ['_c0'])\n","\n","# Add the data to SQL\n","saveToTable(df_exercise, table_census)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6a5c3f99-e343-4af9-ab18-80582b8939b3","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# FOOD SECURITY DATA\n","df_food = readInFile('/mnt/jacklynn/census/Food Insecurity.csv')\n","\n","# Convert state values\n","df_food = catToID(df_food, ['_c0'], ['State'], statesToID)\n","\n","# Rename columns to correct names\n","df_food = renameCols(df_food, ['Year', 'State'], ['year', 'stateID'])\n","\n","# Separate data into two parts\n","for col in ['Food insecurity prevalence', 'Very low food security prevalence']:\n","    \n","    # Get this df\n","    this_df = df_food.select(['year', col, 'stateID'])\n","    \n","    # Format\n","    this_df = this_df.withColumnRenamed(col, 'value')\n","    \n","    # Last metrics\n","    this_df = this_df.withColumn(\"demoID\", lit(demosToID['General']))\n","    if (col == 'Food insecurity prevalence'): \n","        this_df = this_df.withColumn(\"metricID\", lit(metricToID['food security']))\n","    else:\n","        this_df = this_df.withColumn(\"metricID\", lit(metricToID['very low food security']))\n","    \n","    # Add the data to SQL\n","    saveToTable(this_df, table_census)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ba291dde-f2a6-4b8f-a29c-80593638151a","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]},"metadata":{"application/vnd.databricks.v1+output":{"addedWidgets":{},"arguments":{},"data":"<div class=\"ansiout\"></div>","datasetInfos":[],"metadata":{},"removedWidgets":[],"type":"html"}},"output_type":"display_data"}],"source":["# INCOME DATA\n","df_income = readInFile('/mnt/jacklynn/census/Income Brackets by State.csv')\n","\n","# Convert state values\n","df_income = catToID(df_income, ['_c0'], ['State'], statesToID)\n","\n","# Get categories\n","cats = df_income.schema.names\n","for rem_cat in ['_c0', 'Total', 'State', 'Median income (dollars)']:\n","    cats.remove(rem_cat)\n","\n","# Iterate trhoguh categories\n","for cat in cats:\n","    \n","    # Prepare the data\n","    this_df = df_income.select([cat, 'State'])\n","    this_df = addCols(this_df, ['metricID', 'demoID', 'year'], [metricToID['income bracket'], demosToID[cat], 2017])\n","    this_df = renameCols(this_df, ['State', cat], ['stateID', 'value'])\n","    \n","    # Remove percent mark\n","    df_replace = this_df.select(['stateID', 'year', 'value']).toPandas()\n","    for category in ['value']:\n","        df_replace['value'] = df_replace['value'].str.replace('%', '')\n","        df_replace['value'] = df_replace['value'].astype(float)\n","        try:\n","            this_df = this_df.drop(col('value'))\n","        except:\n","            this_df = this_df.drop('value')\n","    df_replace = spark.createDataFrame(df_replace)\n","    this_df = this_df.join(df_replace, on=['stateID', 'year'])\n","    \n","    # Add the data to SQL\n","    saveToTable(this_df, table_census)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"CensusStat-Populator","notebookOrigID":506604325071156,"widgets":{}},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
